{
  "temp" : 0.89999997615814209,
  "repeat_penalty" : 1,
  "add_bos_token" : false,
  "mirostat_tau" : 5,
  "model_inference" : "llama",
  "repeat_last_n" : 64,
  "mmap" : true,
  "add_eos_token" : false,
  "reverse_prompt" : "<|eot_id|>",
  "grammar" : "<None>",
  "prompt_format" : "[system](<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an AI<|eot_id|>)\n\n\n<|start_header_id|>user<|end_header_id|>\n\n\n{prompt}<|eot_id|><|start_header_id|>assistant<|end_header_id|>",
  "top_p" : 0.94999998807907104,
  "parse_special_tokens" : true,
  "top_k" : 40,
  "mirostat" : 0,
  "use_metal" : true,
  "warm_prompt" : "\n\n\n",
  "mlock" : false,
  "tfs_z" : 1,
  "typical_p" : 1,
  "flash_attn" : false,
  "mirostat_eta" : 0.10000000149011612,
  "numberOfThreads" : 10,
  "n_batch" : 512,
  "context" : 1024,
  "template_name" : "LLaMa3 Instruct"
}
